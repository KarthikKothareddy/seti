{"cells":[{"metadata":{"trusted":true,"_uuid":"a4857941b6f359253c907be425829e29d58eeb4b"},"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport time\nimport itertools\n\nfrom sklearn.preprocessing import LabelEncoder\nimport tensorflow as tf\nfrom keras import callbacks\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l1\nfrom keras.layers import Dense, LeakyReLU, Flatten, Dropout\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D, AveragePooling2D\nfrom keras.utils.np_utils import to_categorical\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport matplotlib.pyplot as plt\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"545fda77f9c2ec39fd8bc2aecb8d354c702507c4"},"cell_type":"markdown","source":"We will start by defining some global constants which includes hyper-parameters as well"},{"metadata":{"trusted":true,"_uuid":"4a14a1bbe58c19dd1edc6d4c09e70172ad91b9bf"},"cell_type":"code","source":"# some global constants\nsclasses = [\"brightpixel\",\n            \"narrowband\",\n            \"narrowbanddrd\",\n            \"noise\",\n            \"squarepulsednarrowband\",\n            \"squiggle\",\n            \"squigglesquarepulsednarrowband\"]\n\nmodel_name = \"seti_model\"\nepochs = 100\nlearning_rate = 0.00146\nbatch_size = 50\nsteps_per_epoch = 150\noutput_classes = len(sclasses)\nloss = \"categorical_crossentropy\"\nparameter_scaling = 36\nregularizer = 0.0 #1.0e-7\nmodel_location = \"./model\"\ntensorboard = \"./tensorboard\"\nchannels = 1\npreprocess = True\nclip_outliers = True\npreprocess = True\ngaussian_blurr = False\naugument = True\naugument_size = 200\nimage_width = 384\nimage_hieght = 384\ninput_shape = (image_width, image_hieght, channels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c6bede8e2a77d26faed31e9287de35d2d915b834"},"cell_type":"code","source":"# pre process and image passed \ndef preprocess_image(image, resize=False, grayscale=False):\n    # start by resizing the image\n    if resize:\n        image = cv2.resize(image, (image_width, image_hieght))\n    # if grayscale\n    if grayscale:\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n    if clip_outliers:\n        mean = np.mean(image)\n        std = np.std(image)\n        # clip all the values which are 3.5 standard deviations away from mean\n        image = np.clip(image, mean-3.5*std, mean+3.5*std)\n    if gaussian_blurr:\n        image = cv2.GaussianBlur(image, (3, 3), 1)\n    # morph close \n    morphed = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel=np.ones((3, 3), dtype=np.float32))\n    # gradient in both directions\n    sobelx = cv2.Sobel(morphed, cv2.CV_64F, 1, 0, 2)\n    sobely = cv2.Sobel(morphed, cv2.CV_64F, 0, 1, 2)\n    # final weight with a concentration in horizontal gradient\n    blended = cv2.addWeighted(src1=sobelx, alpha=0.7, src2=sobely, beta=0.3, gamma=0)\n    blended = blended.reshape(image_width, image_hieght, channels)\n    blended = blended/255\n    return blended","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"74412f033abe38a5d93ab397fb9e0cec772abc19"},"cell_type":"code","source":"def augument_images(images=None):\n    datagen = ImageDataGenerator(width_shift_range=0.01,\n                                 height_shift_range=0.01,\n                                 zoom_range=0.01,\n                                 shear_range=0.01,\n                                 horizontal_flip=True,\n                                 vertical_flip=True,\n                                 preprocessing_function=preprocess_image,\n                                 rotation_range=3.0)\n    #datagen.fit(images)\n    #images_batch = next(datagen.flow(x=images, y=None, batch_size=augument_size))\n    return datagen","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"657db4aa7c250fc9f1e8eee8999881a1e4d24b9e"},"cell_type":"code","source":"# gets the data from a directory, applies preprocessing to each image and stores in a numpy array\ndef get_data(primary_dir, augument=False):\n    X = np.empty(shape=(0, image_width, image_hieght, channels))\n    Y = np.empty(shape=(0, ))\n    _global_index = -1\n    for sclass in sclasses:\n        # loop through directories\n        sclass_dir = os.path.join(primary_dir, sclass)\n        print(\"Sclass: {}\".format(sclass))\n        _x = []\n        _y = []\n        for index, filename in enumerate(os.listdir(sclass_dir)):\n            if index % 200 == 0:\n                print(\"Pre-processing {}st image in {} class\".format(index+1, sclass))\n            _global_index += 1\n            _image = cv2.imread(os.path.join(sclass_dir, filename))\n            _image = preprocess_image(_image, resize=True, grayscale=True)\n            # into local list\n            _x.insert(index, _image)\n            _y.insert(index, sclass)\n        # augument to generate more training data\n        if augument:\n            x_aug = augument_images(np.array(_x))\n            y_aug = [sclass]*len(x_aug)\n            _x.extend(x_aug.tolist())\n            _y.extend(y_aug)\n            _global_index += augument_size\n            print(\"Augumented {} images for the class: \\\"{}\\\"\".format(augument_size, sclass))\n        _x = np.array(_x)\n        _y = np.array(_y)\n        # print(\"yshape: {}\".format(_y.shape))\n        # into global list\n        X = np.append(X, _x, axis=0)\n        Y = np.append(Y, _y, axis=0)\n        print(\"Data Extraction complete for class: \\\"{}\\\"\".format(sclass))\n        # print(\"Global Index: {}\".format(_global_index))\n    return X, Y","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f8180aede6fd0051a0c63cf05debba8afe65d62"},"cell_type":"code","source":"def model():\n    scale = parameter_scaling\n    # model architecture\n    _model = Sequential()\n\n    # convolution 1\n    _model.add(Conv2D(scale, (3, 3), input_shape=input_shape))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.2))\n\n    # convolution 2\n    _model.add(Conv2D(2*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 3\n    _model.add(Conv2D(3*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 4\n    _model.add(Conv2D(4*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 5\n    _model.add(Conv2D(5*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 6\n    _model.add(Conv2D(6*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # convolution 7\n    _model.add(Conv2D(7*scale, (3, 3)))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(MaxPooling2D(pool_size=(2, 2)))\n    _model.add(Dropout(0.1))\n\n    # flattening layer\n    _model.add(Flatten())\n\n    # first dense layer\n    _model.add(Dense(units=7*scale))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(Dropout(0.5))\n\n    # second dense layer\n    _model.add(Dense(units=7*scale))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(Dropout(0.5))\n\n    # third dense layer\n    _model.add(Dense(units=7*scale))\n    _model.add(LeakyReLU(alpha=0.1))\n    _model.add(Dropout(0.5))\n\n    # output layer\n    _model.add(Dense(output_classes, activation=\"softmax\"))\n\n    # optimizer\n    _model.compile(Adam(lr=learning_rate), loss=loss, metrics=[\"accuracy\"])\n    print(_model.summary())\n    return _model","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1ead231b07c723f122f9b21e57d731974e8d3469"},"cell_type":"code","source":"def fit(model, train, X_val, y_val, save_model=False):\n        # callbacks\n        h_callbacks = [\n            callbacks.TensorBoard(\n                log_dir=tensorboard,\n                write_graph=True,\n                write_images=False\n            )\n        ]\n        # train on default gpu\n        with tf.device('/gpu:0'):\n            config = tf.ConfigProto()\n            config.gpu_options.allow_growth = True\n            sess = tf.Session(config=config)\n            # fit the data\n            history = model.fit_generator(train,\n                                          epochs=epochs,\n                                          steps_per_epoch=steps_per_epoch,\n                                          validation_data=(X_val, y_val),\n                                          shuffle=True,\n                                          verbose=1,\n                                          callbacks=None)\n        if save_model:\n            # write model configs back\n            with open(os.path.join(model_location, \"{}.json\".format(model_name)), \"w\") as model_json:\n                model_json.write(model.to_json())\n                print(\"Saved Model json to disk\")\n            # save weights to h5\n            model.save_weights(os.path.join(model_location, \"{}.h5\".format(model_name)))\n            print(\"Saved Model weights to disk\")\n        return history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b9b342c94c5ecd0e2dfb3b721640c9bcafd9fdc6"},"cell_type":"code","source":"# wrapper for the fit just in case if needed additional functionality\ndef train(train, X_val, y_val):\n        _model = model()\n        _model.compile(loss=\"categorical_crossentropy\",\n                       optimizer=\"adam\",\n                       metrics=[\"accuracy\"])\n        history = fit(_model, train, X_val, y_val, save_model=False)\n        return _model, history","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"27aaa6ad88dce23bc86d42d3412e8c2bf13a0428","scrolled":true},"cell_type":"code","source":"# train generator because the training data is large and having it in memory is expensive\nimage_generator = augument_images()\ntrain_image_generator = image_generator.flow_from_directory(os.path.join(\"../input/primary_small/train\"),\n                                                           batch_size=batch_size,\n                                                           color_mode=\"grayscale\",\n                                                           target_size=(image_width, image_hieght))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"8119748990db2d0e9dd21601f3a7773fc95f0218","scrolled":true},"cell_type":"code","source":"X_val, y_val = get_data(os.path.join(\"../input/primary_small/valid\"))\nX_test, y_test = get_data(os.path.join(\"../input/primary_small/test\"))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4a251a1096b0028360ece72602322b6cc0def747"},"cell_type":"code","source":"# encode labels\nencoder = LabelEncoder()\nencoder.fit(y_val)\nencoded_ = encoder.transform(y_val)\ny_val = to_categorical(encoded_, output_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"950de5ea26cd544fbe563fe2efd38bf30da5e239"},"cell_type":"code","source":"# train for the given configs\n__model, history = train(train_image_generator, X_val, y_val)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a38e40452f6cd63d8cf771b6b695fe238e732dad","scrolled":false,"_kg_hide-output":false},"cell_type":"code","source":"y_hat = __model.predict_classes(X_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1c0ac46e501b9d7764cd01e3464504c83370fbaf"},"cell_type":"code","source":"encoder_test = LabelEncoder()\nencoder_test.fit(y_test)\nencoded_test = encoder_test.transform(y_test)\ny_test = to_categorical(encoded_test, output_classes)\ny_test = np.argmax(y_test, axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"af7432ba38ec936792042f92df053c98bab7215c"},"cell_type":"code","source":"# plot the loss\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"7b18ac623bbd018ef2a54b0d9d50853ea6c055dc"},"cell_type":"code","source":"# plotting accuracy\nplt.plot(history.history['acc'])\nplt.plot(history.history['val_acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"88e8eb8fe50700c23a9b53348bea3ea0dce1930d"},"cell_type":"code","source":"print(\"Classification Report\")\nprint(classification_report(y_test, y_hat, digits=5))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"967da61795b79a962bddd76700c77b5d33c99aa6"},"cell_type":"code","source":"print(\"Accuracy: {}\".format(accuracy_score(y_test, y_hat)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0314a5c0a4a67b4bfe8f3ebe5bc8b2ed3a32be52"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}